{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1hHMVTCORsg4BtuS2SbxQRwdNC53NOSSA",
      "authorship_tag": "ABX9TyMx6oD3gNIKZHmWXw98Fv+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nivratti/retinaface_ncnn/blob/main/retinaface_ncc_cppVspython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "k_u8vmP_Y0dW",
        "outputId": "3a400565-0ef1-4922-d80b-08408093e764"
      },
      "source": [
        "!pip install jupyter-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 3.13 s (2021-06-01T09:52:11/2021-06-01T09:52:15)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jupyter-autotime in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: ipython<8,>=6 in /usr/local/lib/python3.7/dist-packages (from jupyter-autotime) (7.24.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (0.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (0.18.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (5.0.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (3.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython<8,>=6->jupyter-autotime) (56.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython<8,>=6->jupyter-autotime) (0.8.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython<8,>=6->jupyter-autotime) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython<8,>=6->jupyter-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=6->jupyter-autotime) (0.2.5)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Bmx389yn_Win",
        "outputId": "23ce96c1-4a45-4d00-a84c-2016dd881045"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 1.36 ms (2021-06-01T09:53:56/2021-06-01T09:53:56)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11tfTEk7cKxw"
      },
      "source": [
        "## Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "0pFq4wm_Y7ES",
        "outputId": "8882a28c-54bf-4512-d0f0-e48d16d7039f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 122 ms (2021-06-01T09:52:17/2021-06-01T09:52:17)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  1 09:52:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br2GIGGh7fv_"
      },
      "source": [
        "## Install ncnn (ON GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "4IuUzZldZLZ2",
        "outputId": "ccb6da52-600d-466a-d501-0e89a9d9acad"
      },
      "source": [
        "!sudo apt install build-essential git cmake libprotobuf-dev protobuf-compiler libvulkan-dev vulkan-utils libopencv-dev\n",
        "clear_output()\n",
        "!vulkaninfo | grep deviceType"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 13.1 s (2021-06-01T09:54:22/2021-06-01T09:54:35)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: [Loader Message] Code 0 : loader_icd_scan: Can not find 'ICD' object in ICD JSON file /usr/share/vulkan/icd.d/nvidia_layers.json.  Skipping ICD JSON\n",
            "'DISPLAY' environment variable not set... skipping surface info\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "\tdeviceType     = PHYSICAL_DEVICE_TYPE_DISCRETE_GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "q_Wcw-VT2tXk",
        "outputId": "82ed16c0-db08-4458-be54-d7e0de95801a"
      },
      "source": [
        "%%writefile install_ncnn.sh\n",
        "\n",
        "# https://github.com/Tencent/ncnn/tree/master/python\n",
        "# \n",
        "\n",
        "sudo mkdir -p /usr/local/c++\n",
        "sudo chmod -R 777 /usr/local/c++\n",
        "cd /usr/local/c++/\n",
        "git clone https://github.com/Tencent/ncnn.git\n",
        "cd ncnn\n",
        "git submodule init && git submodule update\n",
        "\n",
        "mkdir -p build && cd build\n",
        "\n",
        "# set DNCNN_VULKAN=ON on GPU\n",
        "sudo cmake -DCMAKE_BUILD_TYPE=Release -DNCNN_VULKAN=ON -DNCNN_PYTHON=ON -DNCNN_SYSTEM_GLSLANG=ON -DNCNN_BUILD_EXAMPLES=ON ..\n",
        "sudo make -j$(nproc)\n",
        "sudo make install\n",
        "\n",
        "# -------------------------------------------------\n",
        "# python\n",
        "# -------------------------------------------------\n",
        "#     Install\n",
        "\n",
        "#         cd /pathto/ncnn/python\n",
        "#         pip install .\n",
        "\n",
        "#     if you use conda or miniconda, you can also install as following:\n",
        "\n",
        "#         cd /pathto/ncnn/python\n",
        "#         python3 setup.py install\n",
        "\n",
        "\n",
        "cd ../python\n",
        "pip3 install .\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Model Zoo\n",
        "# -----------------------------------------------------\n",
        "\n",
        "# install requirements\n",
        "\n",
        "#     pip install -r requirements.txt\n",
        "\n",
        "# then you can import ncnn.model_zoo and get model list as follow:\n",
        "\n",
        "#     import ncnn\n",
        "#     import ncnn.model_zoo as model_zoo\n",
        "\n",
        "#     print(model_zoo.get_model_list())\n",
        "\n",
        "pip3 install -r requirements.txt\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# cmd usage\n",
        "# ---------------------------------------------------\n",
        "# python examples/retinaface.py  \"path/to/image\"\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 4.92 ms (2021-06-01T09:55:22/2021-06-01T09:55:22)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Writing install_ncnn.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "1i_IaDl66JZE",
        "outputId": "b448a609-6d09-4ef6-f47f-048ff6ed5429"
      },
      "source": [
        "!sudo bash ./install_ncnn.sh\n",
        "\n",
        "clear_output()\n",
        "print(\"Ncnn installation completed..\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ncnn installation completed..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 6 min 14 s (2021-06-01T09:55:28/2021-06-01T10:01:43)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFnEk-zL8Ylb"
      },
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TO8yul1d8f6t",
        "outputId": "515b71e0-7ad0-406e-ad29-12b79b51426a"
      },
      "source": [
        "import ncnn\n",
        "import ncnn.model_zoo as model_zoo\n",
        "\n",
        "print(model_zoo.get_model_list())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 4.4 ms (2021-06-01T10:03:36/2021-06-01T10:03:36)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['mobilenet_yolov2', 'mobilenetv2_yolov3', 'yolov4_tiny', 'yolov4', 'yolov5s', 'yolact', 'mobilenet_ssd', 'squeezenet_ssd', 'mobilenetv2_ssdlite', 'mobilenetv3_ssdlite', 'squeezenet', 'faster_rcnn', 'peleenet_ssd', 'retinaface', 'rfcn', 'shufflenetv2', 'simplepose', 'nanodet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uiqse3wfzm3"
      },
      "source": [
        "## Python ncnn retinaface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29u10FiJfz2D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03b17740-dc56-43db-a498-beca13130f44"
      },
      "source": [
        "#@title Modified retinaface.py\n",
        "\n",
        "# https://raw.githubusercontent.com/Tencent/ncnn/master/python/ncnn/model_zoo/retinaface.py\n",
        "\n",
        "## Modification\n",
        "# Added support to use resnet-50 --Accurate face detector instead of mnet\n",
        "\n",
        "import numpy as np\n",
        "import ncnn\n",
        "from ncnn.model_zoo.model_store import get_model_file\n",
        "from ncnn.utils.objects import Point, Face_Object\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "home = str(Path.home())\n",
        "\n",
        "\n",
        "class RetinaFace:\n",
        "    def __init__(\n",
        "        self, prob_threshold=0.8, nms_threshold=0.4, num_threads=1, use_gpu=False, model=\"resnet50\"\n",
        "    ):\n",
        "        self.prob_threshold = prob_threshold\n",
        "        self.nms_threshold = nms_threshold\n",
        "        self.num_threads = num_threads\n",
        "        self.use_gpu = use_gpu\n",
        "\n",
        "        self.net = ncnn.Net()\n",
        "        self.net.opt.use_vulkan_compute = self.use_gpu\n",
        "\n",
        "        # model is converted from\n",
        "        # https://github.com/deepinsight/insightface/tree/master/RetinaFace#retinaface-pretrained-models\n",
        "        # https://github.com/deepinsight/insightface/issues/669\n",
        "        # the ncnn model https://github.com/nihui/ncnn-assets/tree/master/models\n",
        "\n",
        "        if model == \"resnet50\":\n",
        "            param_file = os.path.join(home, 'retinaface-R50.param')\n",
        "            if not os.path.exists(param_file):\n",
        "                url = 'https://drive.google.com/uc?id=1qCKoY8NfnhCPjOgXcymKDDXh3AjFXda6'\n",
        "                gdown.download(url, param_file, quiet=False)\n",
        "\n",
        "            model_file = os.path.join(home, 'retinaface-R50.bin')\n",
        "            if not os.path.exists(model_file):\n",
        "                url = 'https://drive.google.com/uc?id=1_WBTqDcQoF0soCjuHYdJs3IO9soznBp4'\n",
        "                gdown.download(url, model_file, quiet=False)\n",
        "\n",
        "            self.net.load_param(param_file)\n",
        "            self.net.load_model(model_file)\n",
        "\n",
        "        else:\n",
        "            ## mnet\n",
        "            self.net.load_param(get_model_file(\"mnet.25-opt.param\"))\n",
        "            self.net.load_model(get_model_file(\"mnet.25-opt.bin\"))\n",
        "\n",
        "\n",
        "    def __del__(self):\n",
        "        self.net = None\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img_h = img.shape[0]\n",
        "        img_w = img.shape[1]\n",
        "\n",
        "        mat_in = ncnn.Mat.from_pixels(\n",
        "            img, ncnn.Mat.PixelType.PIXEL_BGR2RGB, img_w, img_h\n",
        "        )\n",
        "\n",
        "        ex = self.net.create_extractor()\n",
        "        ex.set_num_threads(self.num_threads)\n",
        "\n",
        "        ex.input(\"data\", mat_in)\n",
        "\n",
        "        faceobjects32 = self.detect_stride32(ex)\n",
        "        faceobjects16 = self.detect_stride16(ex)\n",
        "        faceobjects8 = self.detect_stride8(ex)\n",
        "\n",
        "        faceproposals = [*faceobjects32, *faceobjects16, *faceobjects8]\n",
        "\n",
        "        # sort all proposals by score from highest to lowest\n",
        "        faceproposals.sort(key=lambda obj: obj.prob, reverse=True)\n",
        "\n",
        "        # apply nms with nms_threshold\n",
        "        picked = self.nms_sorted_bboxes(faceproposals, self.nms_threshold)\n",
        "\n",
        "        face_count = len(picked)\n",
        "\n",
        "        faceobjects = []\n",
        "        for i in range(face_count):\n",
        "            faceobjects.append(faceproposals[picked[i]])\n",
        "\n",
        "            # clip to image size\n",
        "            x0 = faceobjects[i].rect.x\n",
        "            y0 = faceobjects[i].rect.y\n",
        "            x1 = x0 + faceobjects[i].rect.w\n",
        "            y1 = y0 + faceobjects[i].rect.h\n",
        "\n",
        "            x0 = np.maximum(np.minimum(x0, float(img_w) - 1), 0.0)\n",
        "            y0 = np.maximum(np.minimum(y0, float(img_h) - 1), 0.0)\n",
        "            x1 = np.maximum(np.minimum(x1, float(img_w) - 1), 0.0)\n",
        "            y1 = np.maximum(np.minimum(y1, float(img_h) - 1), 0.0)\n",
        "\n",
        "            faceobjects[i].rect.x = x0\n",
        "            faceobjects[i].rect.y = y0\n",
        "            faceobjects[i].rect.w = x1 - x0\n",
        "            faceobjects[i].rect.h = y1 - y0\n",
        "\n",
        "        return faceobjects\n",
        "\n",
        "    def detect_stride32(self, ex):\n",
        "        ret1, score_blob = ex.extract(\"face_rpn_cls_prob_reshape_stride32\")\n",
        "        ret2, bbox_blob = ex.extract(\"face_rpn_bbox_pred_stride32\")\n",
        "        ret3, landmark_blob = ex.extract(\"face_rpn_landmark_pred_stride32\")\n",
        "\n",
        "        base_size = 16\n",
        "        feat_stride = 32\n",
        "        ratios = ncnn.Mat(1)\n",
        "        ratios[0] = 1.0\n",
        "        scales = ncnn.Mat(2)\n",
        "        scales[0] = 32.0\n",
        "        scales[1] = 16.0\n",
        "        anchors = self.generate_anchors(base_size, ratios, scales)\n",
        "\n",
        "        faceobjects32 = self.generate_proposals(\n",
        "            anchors,\n",
        "            feat_stride,\n",
        "            score_blob,\n",
        "            bbox_blob,\n",
        "            landmark_blob,\n",
        "            self.prob_threshold,\n",
        "        )\n",
        "\n",
        "        return faceobjects32\n",
        "\n",
        "    def detect_stride16(self, ex):\n",
        "        ret1, score_blob = ex.extract(\"face_rpn_cls_prob_reshape_stride16\")\n",
        "        ret2, bbox_blob = ex.extract(\"face_rpn_bbox_pred_stride16\")\n",
        "        ret3, landmark_blob = ex.extract(\"face_rpn_landmark_pred_stride16\")\n",
        "\n",
        "        base_size = 16\n",
        "        feat_stride = 16\n",
        "        ratios = ncnn.Mat(1)\n",
        "        ratios[0] = 1.0\n",
        "        scales = ncnn.Mat(2)\n",
        "        scales[0] = 8.0\n",
        "        scales[1] = 4.0\n",
        "        anchors = self.generate_anchors(base_size, ratios, scales)\n",
        "\n",
        "        faceobjects16 = self.generate_proposals(\n",
        "            anchors,\n",
        "            feat_stride,\n",
        "            score_blob,\n",
        "            bbox_blob,\n",
        "            landmark_blob,\n",
        "            self.prob_threshold,\n",
        "        )\n",
        "\n",
        "        return faceobjects16\n",
        "\n",
        "    def detect_stride8(self, ex):\n",
        "        ret1, score_blob = ex.extract(\"face_rpn_cls_prob_reshape_stride8\")\n",
        "        ret2, bbox_blob = ex.extract(\"face_rpn_bbox_pred_stride8\")\n",
        "        ret3, landmark_blob = ex.extract(\"face_rpn_landmark_pred_stride8\")\n",
        "\n",
        "        base_size = 16\n",
        "        feat_stride = 8\n",
        "        ratios = ncnn.Mat(1)\n",
        "        ratios[0] = 1.0\n",
        "        scales = ncnn.Mat(2)\n",
        "        scales[0] = 2.0\n",
        "        scales[1] = 1.0\n",
        "        anchors = self.generate_anchors(base_size, ratios, scales)\n",
        "\n",
        "        faceobjects8 = self.generate_proposals(\n",
        "            anchors,\n",
        "            feat_stride,\n",
        "            score_blob,\n",
        "            bbox_blob,\n",
        "            landmark_blob,\n",
        "            self.prob_threshold,\n",
        "        )\n",
        "\n",
        "        return faceobjects8\n",
        "\n",
        "    def generate_anchors(self, base_size, ratios, scales):\n",
        "        num_ratio = ratios.w\n",
        "        num_scale = scales.w\n",
        "\n",
        "        # anchors = ncnn.Mat()\n",
        "        # anchors.create(w=4, h=num_ratio * num_scale)\n",
        "\n",
        "        anchors_np = np.zeros((2, 4), dtype=np.float32)\n",
        "\n",
        "        cx = base_size * 0.5\n",
        "        cy = base_size * 0.5\n",
        "\n",
        "        for i in range(num_ratio):\n",
        "            ar = ratios[i]\n",
        "\n",
        "            r_w = np.round(base_size / np.sqrt(ar))\n",
        "            r_h = np.round(r_w * ar)  # round(base_size * np.sqrt(ar))\n",
        "\n",
        "            for j in range(num_scale):\n",
        "                scale = scales[j]\n",
        "\n",
        "                rs_w = r_w * scale\n",
        "                rs_h = r_h * scale\n",
        "\n",
        "                anchor = anchors_np[i * num_scale + j]\n",
        "\n",
        "                anchor[0] = cx - rs_w * 0.5\n",
        "                anchor[1] = cy - rs_h * 0.5\n",
        "                anchor[2] = cx + rs_w * 0.5\n",
        "                anchor[3] = cy + rs_h * 0.5\n",
        "\n",
        "        anchors = ncnn.Mat(anchors_np)\n",
        "        return anchors\n",
        "\n",
        "    def generate_proposals(\n",
        "        self, anchors, feat_stride, score_blob, bbox_blob, landmark_blob, prob_threshold\n",
        "    ):\n",
        "        faceobjects = []\n",
        "\n",
        "        w = score_blob.w\n",
        "        h = score_blob.h\n",
        "\n",
        "        # generate face proposal from bbox deltas and shifted anchors\n",
        "        num_anchors = anchors.h\n",
        "\n",
        "        for q in range(num_anchors):\n",
        "            anchor = anchors.row(q)\n",
        "\n",
        "            score = score_blob.channel(q + num_anchors)\n",
        "            bbox = bbox_blob.channel_range(q * 4, 4)\n",
        "            landmark = landmark_blob.channel_range(q * 10, 10)\n",
        "\n",
        "            # shifted anchor\n",
        "            anchor_y = anchor[1]\n",
        "\n",
        "            anchor_w = anchor[2] - anchor[0]\n",
        "            anchor_h = anchor[3] - anchor[1]\n",
        "\n",
        "            for i in range(h):\n",
        "                anchor_x = anchor[0]\n",
        "\n",
        "                for j in range(w):\n",
        "                    index = i * w + j\n",
        "\n",
        "                    prob = score[index]\n",
        "\n",
        "                    if prob >= prob_threshold:\n",
        "                        # apply center size\n",
        "                        dx = bbox.channel(0)[index]\n",
        "                        dy = bbox.channel(1)[index]\n",
        "                        dw = bbox.channel(2)[index]\n",
        "                        dh = bbox.channel(3)[index]\n",
        "\n",
        "                        cx = anchor_x + anchor_w * 0.5\n",
        "                        cy = anchor_y + anchor_h * 0.5\n",
        "\n",
        "                        pb_cx = cx + anchor_w * dx\n",
        "                        pb_cy = cy + anchor_h * dy\n",
        "\n",
        "                        pb_w = anchor_w * np.exp(dw)\n",
        "                        pb_h = anchor_h * np.exp(dh)\n",
        "\n",
        "                        x0 = pb_cx - pb_w * 0.5\n",
        "                        y0 = pb_cy - pb_h * 0.5\n",
        "                        x1 = pb_cx + pb_w * 0.5\n",
        "                        y1 = pb_cy + pb_h * 0.5\n",
        "\n",
        "                        obj = Face_Object()\n",
        "                        obj.rect.x = x0\n",
        "                        obj.rect.y = y0\n",
        "                        obj.rect.w = x1 - x0 + 1\n",
        "                        obj.rect.h = y1 - y0 + 1\n",
        "                        obj.landmark = [Point(), Point(), Point(), Point(), Point()]\n",
        "                        obj.landmark[0].x = (\n",
        "                            cx + (anchor_w + 1) * landmark.channel(0)[index]\n",
        "                        )\n",
        "                        obj.landmark[0].y = (\n",
        "                            cy + (anchor_h + 1) * landmark.channel(1)[index]\n",
        "                        )\n",
        "                        obj.landmark[1].x = (\n",
        "                            cx + (anchor_w + 1) * landmark.channel(2)[index]\n",
        "                        )\n",
        "                        obj.landmark[1].y = (\n",
        "                            cy + (anchor_h + 1) * landmark.channel(3)[index]\n",
        "                        )\n",
        "                        obj.landmark[2].x = (\n",
        "                            cx + (anchor_w + 1) * landmark.channel(4)[index]\n",
        "                        )\n",
        "                        obj.landmark[2].y = (\n",
        "                            cy + (anchor_h + 1) * landmark.channel(5)[index]\n",
        "                        )\n",
        "                        obj.landmark[3].x = (\n",
        "                            cx + (anchor_w + 1) * landmark.channel(6)[index]\n",
        "                        )\n",
        "                        obj.landmark[3].y = (\n",
        "                            cy + (anchor_h + 1) * landmark.channel(7)[index]\n",
        "                        )\n",
        "                        obj.landmark[4].x = (\n",
        "                            cx + (anchor_w + 1) * landmark.channel(8)[index]\n",
        "                        )\n",
        "                        obj.landmark[4].y = (\n",
        "                            cy + (anchor_h + 1) * landmark.channel(9)[index]\n",
        "                        )\n",
        "                        obj.prob = prob\n",
        "\n",
        "                        faceobjects.append(obj)\n",
        "\n",
        "                    anchor_x += feat_stride\n",
        "\n",
        "                anchor_y += feat_stride\n",
        "\n",
        "        return faceobjects\n",
        "\n",
        "    def nms_sorted_bboxes(self, faceobjects, nms_threshold):\n",
        "        picked = []\n",
        "\n",
        "        n = len(faceobjects)\n",
        "\n",
        "        areas = []\n",
        "        for i in range(n):\n",
        "            areas.append(faceobjects[i].rect.area())\n",
        "\n",
        "        for i in range(n):\n",
        "            a = faceobjects[i]\n",
        "\n",
        "            keep = True\n",
        "            for j in range(len(picked)):\n",
        "                b = faceobjects[picked[j]]\n",
        "\n",
        "                # intersection over union\n",
        "                inter_area = a.rect.intersection_area(b.rect)\n",
        "                union_area = areas[i] + areas[picked[j]] - inter_area\n",
        "                # float IoU = inter_area / union_area\n",
        "                if inter_area / union_area > nms_threshold:\n",
        "                    keep = False\n",
        "\n",
        "            if keep:\n",
        "                picked.append(i)\n",
        "\n",
        "        return picked\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 955 ms (2021-06-01T11:22:38/2021-06-01T11:22:39)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_2nbPoAf-Y9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78f5f037-297d-4e48-e4bb-6ee095e1b4c7"
      },
      "source": [
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import ncnn\n",
        "# from ncnn.model_zoo import get_model\n",
        "from ncnn.utils import draw_faceobjects\n",
        "\n",
        "\n",
        "class FaceDetectionRTncnn:\n",
        "    def __init__(self, prob_threshold=0.8, nms_threshold=0.4, num_threads=4, use_gpu=False, model=\"resnet50\"):\n",
        "        self.net = RetinaFace(\n",
        "            prob_threshold=prob_threshold, nms_threshold=nms_threshold, num_threads=num_threads, use_gpu=use_gpu, \n",
        "            model=model\n",
        "        )\n",
        "\n",
        "    def get_face_bbox(self, img_bgr, max_faces=0, return_boxformat=\"xywh\", is_draw_faceobjects=False):\n",
        "        \"\"\"\n",
        "        Get face box\n",
        "\n",
        "        Args:\n",
        "            img_bgr (opencv): Opencv image in bgr default format\n",
        "            max_faces (int, optional): If 0 return all face counts. Defaults to 0.\n",
        "            return_boxformat (str, optional): If xywh return x,y and width and height. Defaults to \"xywh\".\n",
        "                                            else x1y1-x2y2 - x, y , x+ w, x + height\n",
        "        \"\"\"\n",
        "        def _get_box(obj, return_boxformat=\"xywh\"):\n",
        "            if return_boxformat == \"xywh\":\n",
        "                bbox = [\n",
        "                    round(obj.rect.x), round(obj.rect.y), round(obj.rect.w), round(obj.rect.h), obj.prob # xywh format\n",
        "                ]\n",
        "            else:\n",
        "                # x1y1-x2y2\n",
        "                bbox = [\n",
        "                    round(obj.rect.x), round(obj.rect.y), \n",
        "                    round(obj.rect.x + obj.rect.w), round(obj.rect.y + obj.rect.h), \n",
        "                    obj.prob # x1y1x2y2 facebox format\n",
        "                ]\n",
        "            return bbox\n",
        "\n",
        "        faceobjects = self.net(img_bgr)\n",
        "\n",
        "        # for obj in faceobjects:\n",
        "        #     print(\n",
        "        #         \"%.5f at %.2f %.2f %.2f x %.2f\"\n",
        "        #         % (obj.prob, obj.rect.x, obj.rect.y, obj.rect.w, obj.rect.h)\n",
        "        #     )\n",
        "\n",
        "        if is_draw_faceobjects:\n",
        "            draw_faceobjects(img_bgr, faceobjects)\n",
        "            \n",
        "        if max_faces <= 0 or max_faces >=2:\n",
        "            face_boxes = []\n",
        "            for idx, obj in enumerate(faceobjects, start=1):\n",
        "                print(f\"obj.rect.x: {obj.rect.x}\")\n",
        "                print(f\"obj.rect.y: {obj.rect.y}\")\n",
        "                print(f\"obj.rect.w: {obj.rect.w}\")\n",
        "                print(f\"obj.rect.h: {obj.rect.h}\")\n",
        "\n",
        "                bbox = _get_box(obj, return_boxformat=\"xywh\")\n",
        "                face_boxes.append(bbox)\n",
        "                if idx == max_faces:\n",
        "                    break\n",
        "            return face_boxes\n",
        "        else:\n",
        "            # return singal high confidence face\n",
        "            if len(faceobjects) >= 1:\n",
        "                return _get_box(faceobjects[0], return_boxformat=\"xywh\")\n",
        "            else:\n",
        "                return []"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 54.2 ms (2021-06-01T11:44:24/2021-06-01T11:44:24)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "okLYfs_ygGSd",
        "outputId": "47e1e98a-fdba-43cb-e8f9-333310477ed5"
      },
      "source": [
        "face_detector = FaceDetectionRTncnn(use_gpu=True)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 1.39 s (2021-06-01T11:58:16/2021-06-01T11:58:18)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "nWiEjhsmgJUM",
        "outputId": "05cc633a-4b81-4697-eef1-3003076469bb"
      },
      "source": [
        "# from ncnn.utils import draw_faceobjects\n",
        "# imagepath = \"/content/human.png\"\n",
        "imagepath = \"/content/pan-card-500x500.jpg\"\n",
        "# imagepath = \"/content/Woman Wearing White Shirt Waving Goodbye.jpg\"\n",
        "\n",
        "img_bgr = cv2.imread(imagepath)\n",
        "if img_bgr is None:\n",
        "    print(\"cv2.imread %s failed\\n\" % (imagepath))\n",
        "    sys.exit(0)\n",
        "\n",
        "face_boxes = face_detector.get_face_bbox(\n",
        "    img_bgr, max_faces=2,\n",
        "    return_boxformat=\"xywh\",\n",
        "    is_draw_faceobjects=False\n",
        ")\n",
        "print(f\"\\nface_boxes: {face_boxes}\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 117 ms (2021-06-01T11:58:28/2021-06-01T11:58:28)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "obj.rect.x: 381.5889571369823\n",
            "obj.rect.y: 208.69838688128922\n",
            "obj.rect.w: 56.583804476035425\n",
            "obj.rect.h: 71.11885123742152\n",
            "\n",
            "face_boxes: [[382, 209, 57, 71, 0.9970703125]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLqb9tQrb0wn"
      },
      "source": [
        "faceobjects[0].rect.x: 381.596\n",
        "faceobjects[0].rect.y: 208.707\n",
        "faceobjects[0].rect.width: 56.569\n",
        "faceobjects[0].rect.height: 71.1753\n",
        "\n",
        "obj.rect.x: 381.59588212797877\n",
        "obj.rect.y: 208.70658384260472\n",
        "obj.rect.w: 56.56897888521678\n",
        "obj.rect.h: 71.17527034884822"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAjQN5ZCaTjw"
      },
      "source": [
        "obj.rect.x: 808.7731370958414\n",
        "obj.rect.y: 151.8726988363982\n",
        "obj.rect.w: 339.32872580831724\n",
        "obj.rect.h: 487.12960232720366"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75rCfaOfjkoE"
      },
      "source": [
        "Cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "id": "KBQMH1oYjl4l",
        "outputId": "c2ec3af6-c8dd-4120-8b88-39c034aea4b1"
      },
      "source": [
        "#@title Image scaling cropping utility\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CropImage:\n",
        "    \"\"\"\n",
        "    Create patch from original input image by using bbox coordinate\n",
        "\n",
        "    Usage:\n",
        "        image_cropper = CropImage()\n",
        "\n",
        "        image_bbox = face_box\n",
        "        w_input = 224\n",
        "        h_input = 224\n",
        "\n",
        "        scale = 1.45\n",
        "\n",
        "        param = {\n",
        "            \"org_img\": image,\n",
        "            \"bbox\": image_bbox,\n",
        "            \"scale\": scale,\n",
        "            \"out_w\": w_input,\n",
        "            \"out_h\": h_input,\n",
        "            \"crop\": True,\n",
        "        }\n",
        "        if scale is None:\n",
        "            param[\"crop\"] = False\n",
        "\n",
        "        patch_cropped_img = image_cropper.crop(**param)\n",
        "        print(f\"patch_cropped_img.shape : {patch_cropped_img.shape}\")\n",
        "        display(Image.fromarray(patch_cropped_img))\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def _get_new_box(src_w, src_h, bbox, scale):\n",
        "        x = bbox[0]\n",
        "        y = bbox[1]\n",
        "        box_w = bbox[2]\n",
        "        box_h = bbox[3]\n",
        "\n",
        "        scale = min((src_h-1)/box_h, min((src_w-1)/box_w, scale))\n",
        "\n",
        "        new_width = box_w * scale\n",
        "        new_height = box_h * scale\n",
        "        center_x, center_y = box_w/2+x, box_h/2+y\n",
        "\n",
        "        left_top_x = center_x-new_width/2\n",
        "        left_top_y = center_y-new_height/2\n",
        "        right_bottom_x = center_x+new_width/2\n",
        "        right_bottom_y = center_y+new_height/2\n",
        "\n",
        "        if left_top_x < 0:\n",
        "            right_bottom_x -= left_top_x\n",
        "            left_top_x = 0\n",
        "\n",
        "        if left_top_y < 0:\n",
        "            right_bottom_y -= left_top_y\n",
        "            left_top_y = 0\n",
        "\n",
        "        if right_bottom_x > src_w-1:\n",
        "            left_top_x -= right_bottom_x-src_w+1\n",
        "            right_bottom_x = src_w-1\n",
        "\n",
        "        if right_bottom_y > src_h-1:\n",
        "            left_top_y -= right_bottom_y-src_h+1\n",
        "            right_bottom_y = src_h-1\n",
        "\n",
        "        return int(left_top_x), int(left_top_y),\\\n",
        "               int(right_bottom_x), int(right_bottom_y)\n",
        "\n",
        "    def crop_patch(self, org_img, bbox, scale, out_w, out_h, crop=True):\n",
        "\n",
        "        if not crop:\n",
        "            dst_img = cv2.resize(org_img, (out_w, out_h))\n",
        "        else:\n",
        "            src_h, src_w, _ = np.shape(org_img)\n",
        "            left_top_x, left_top_y, \\\n",
        "                right_bottom_x, right_bottom_y = self._get_new_box(src_w, src_h, bbox, scale)\n",
        "\n",
        "            print(f\"New facebox:\")\n",
        "            print(f\"{left_top_x}, {left_top_y}, {right_bottom_x}, {right_bottom_y}\")\n",
        "\n",
        "            img = org_img[left_top_y: right_bottom_y+1,\n",
        "                          left_top_x: right_bottom_x+1]\n",
        "            dst_img = cv2.resize(img, (out_w, out_h))\n",
        "        return dst_img\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 64.1 ms (2021-06-01T11:23:01/2021-06-01T11:23:01)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "iR3ibvlkkLRj",
        "outputId": "fdc0c527-c18d-4aed-a47f-aefe2c6f360c"
      },
      "source": [
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "\n",
        "image_cropper = CropImage()\n",
        "\n",
        "image_bbox = face_boxes[0] # face_box\n",
        "w_input = 224\n",
        "h_input = 224\n",
        "\n",
        "scale = 2.0\n",
        "\n",
        "param = {\n",
        "    \"org_img\": img_bgr,\n",
        "    \"bbox\": image_bbox,\n",
        "    \"scale\": scale,\n",
        "    \"out_w\": w_input,\n",
        "    \"out_h\": h_input,\n",
        "    \"crop\": True,\n",
        "}\n",
        "if scale is None:\n",
        "    param[\"crop\"] = False\n",
        "\n",
        "patch_cropped_img = image_cropper.crop_patch(**param)\n",
        "# print(f\"patch_cropped_img.shape : {patch_cropped_img.shape}\")\n",
        "# display(Image.fromarray(patch_cropped_img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 14.6 ms (2021-05-31T13:23:33/2021-05-31T13:23:33)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "New facebox:\n",
            "353, 169, 467, 311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxIGp2vhij3o"
      },
      "source": [
        "## C++ ncnn retinaface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ugBjk_krPLG"
      },
      "source": [
        "### Setup Opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9KRVpRkimdI",
        "outputId": "f84d4394-c687-4b70-d097-7ca0153f8927"
      },
      "source": [
        "%cd \"/content\"\n",
        "!git clone https://github.com/microsoft/vcpkg\n",
        "!./vcpkg/bootstrap-vcpkg.sh"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 3 min 55 s (2021-06-01T10:12:22/2021-06-01T10:16:18)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vcpkg'...\n",
            "remote: Enumerating objects: 111589, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 111589 (delta 17), reused 13 (delta 2), pack-reused 111540\u001b[K\n",
            "Receiving objects: 100% (111589/111589), 34.43 MiB | 20.83 MiB/s, done.\n",
            "Resolving deltas: 100% (70387/70387), done.\n",
            "Downloading cmake...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   634  100   634    0     0   3123      0 --:--:-- --:--:-- --:--:--  3123\n",
            "100 41.5M  100 41.5M    0     0  44.0M      0 --:--:-- --:--:-- --:--:-- 90.6M\n",
            "Downloading cmake... done.\n",
            "Extracting cmake...\n",
            "Extracting cmake... done.\n",
            "Downloading ninja...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   619  100   619    0     0  13456      0 --:--:-- --:--:-- --:--:-- 13456\n",
            "100 99913  100 99913    0     0   587k      0 --:--:-- --:--:-- --:--:--  587k\n",
            "Downloading ninja... done.\n",
            "Extracting ninja...\n",
            "Extracting ninja... done.\n",
            "Downloading vcpkg tool sources\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   173  100   173    0     0   1005      0 --:--:-- --:--:-- --:--:--  1005\n",
            "100  494k  100  494k    0     0  1217k      0 --:--:-- --:--:-- --:--:-- 1217k\n",
            "Building vcpkg-tool...\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/g++-7 - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Detecting the C++ compiler in use\n",
            "-- Detecting the C++ compiler in use - gcc\n",
            "-- Detecting the C++ standard library\n",
            "-- Detecting the C++ standard library - libstdc++\n",
            "-- Detecting how to use the C++ filesystem library\n",
            "-- Detecting how to use the C++ filesystem library - <experimental/filesystem> with -lstdc++fs\n",
            "-- Looking for C++ include pthread.h\n",
            "-- Looking for C++ include pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
            "-- Check if compiler accepts -pthread\n",
            "-- Check if compiler accepts -pthread - yes\n",
            "-- Found Threads: TRUE  \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/vcpkg/buildtrees/_vcpkg/build\n",
            "[0/2] Re-checking globbed directories...\u001b[K\n",
            "[91/91] Linking CXX executable vcpkg\u001b[K\n",
            "Telemetry\n",
            "---------\n",
            "vcpkg collects usage data in order to help us improve your experience.\n",
            "The data collected by Microsoft is anonymous.\n",
            "You can opt-out of telemetry by re-running the bootstrap-vcpkg script with -disableMetrics,\n",
            "passing --disable-metrics to vcpkg on the command line,\n",
            "or by setting the VCPKG_DISABLE_METRICS environment variable.\n",
            "\n",
            "Read more about vcpkg telemetry at docs/about/privacy.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tcu3D9YVD9MP",
        "outputId": "8bd5072b-0576-4b88-b3f0-b1d67646894a"
      },
      "source": [
        "# # Search packages over vcpkg\n",
        "# # $ ./vcpkg/vcpkg search [search term]\n",
        "!./vcpkg/vcpkg search opencv"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 1.31 s (2021-06-01T10:23:21/2021-06-01T10:23:23)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "darknet[opencv-base]                  Build darknet with support for latest version of OpenCV\n",
            "darknet[opencv-cuda]                  Build darknet with support for latest version of CUDA-enabled OpenCV\n",
            "darknet[opencv2-base]                 Build darknet with support for OpenCV2\n",
            "darknet[opencv2-cuda]                 Build darknet with support for CUDA-enabled OpenCV2\n",
            "darknet[opencv3-base]                 Build darknet with support for OpenCV3\n",
            "darknet[opencv3-cuda]                 Build darknet with support for CUDA-enabled OpenCV3\n",
            "matplotplusplus[opencv]               opencv support for Matplot++\n",
            "opencv               4.5.1            Computer vision library\n",
            "opencv[ade]                           graph api\n",
            "opencv[contrib]                       opencv_contrib module\n",
            "opencv[cuda]                          CUDA support for opencv\n",
            "opencv[dnn]                           Enable dnn module\n",
            "opencv[eigen]                         Eigen support for opencv\n",
            "opencv[ffmpeg]                        ffmpeg support for opencv\n",
            "opencv[gdcm]                          GDCM support for opencv\n",
            "opencv[halide]                        Halide support for opencv\n",
            "opencv[ipp]                           Enable Intel Integrated Performance Primitives\n",
            "opencv[jasper]                        JPEG 2000 support for opencv\n",
            "opencv[jpeg]                          JPEG support for opencv\n",
            "opencv[lapack]                        LAPACK support for opencv\n",
            "opencv[nonfree]                       opencv nonfree module\n",
            "opencv[openexr]                       OpenEXR support for opencv\n",
            "opencv[opengl]                        opengl support for opencv\n",
            "opencv[openmp]                        Enable openmp support for opencv\n",
            "opencv[ovis]                          opencv_ovis module\n",
            "opencv[png]                           PNG support for opencv\n",
            "opencv[qt]                            Qt GUI support for opencv\n",
            "opencv[quirc]                         Enable QR code module\n",
            "opencv[sfm]                           opencv_sfm module\n",
            "opencv[tbb]                           Enable Intel Threading Building Blocks\n",
            "opencv[tiff]                          TIFF support for opencv\n",
            "opencv[vtk]                           vtk support for opencv\n",
            "opencv[webp]                          WebP support for opencv\n",
            "opencv[world]                         Compile to a single package support for opencv\n",
            "opencv2              2.4.13.7#5       computer vision library, version 2\n",
            "opencv2[cuda]                         CUDA support for opencv\n",
            "opencv2[eigen]                        Eigen support for opencv\n",
            "opencv2[ffmpeg]                       ffmpeg support for opencv\n",
            "opencv2[jasper]                       JPEG 2000 support for opencv\n",
            "opencv2[jpeg]                         JPEG support for opencv\n",
            "opencv2[openexr]                      OpenEXR support for opencv\n",
            "opencv2[opengl]                       opengl support for opencv\n",
            "opencv2[png]                          PNG support for opencv\n",
            "opencv2[qt]                           Qt GUI support for opencv\n",
            "opencv2[tiff]                         TIFF support for opencv\n",
            "opencv2[world]                        Compile to a single package support for opencv\n",
            "opencv3              3.4.13           computer vision library\n",
            "opencv3[contrib]                      opencv_contrib module\n",
            "opencv3[cuda]                         CUDA support for opencv\n",
            "opencv3[dnn]                          Enable dnn module\n",
            "opencv3[eigen]                        Eigen support for opencv\n",
            "opencv3[ffmpeg]                       ffmpeg support for opencv\n",
            "opencv3[flann]                        opencv_flann module\n",
            "opencv3[gdcm]                         GDCM support for opencv\n",
            "opencv3[halide]                       Halide support for opencv\n",
            "opencv3[ipp]                          Enable Intel Integrated Performance Primitives\n",
            "opencv3[jasper]                       JPEG 2000 support for opencv\n",
            "opencv3[jpeg]                         JPEG support for opencv\n",
            "opencv3[lapack]                       LAPACK support for opencv\n",
            "opencv3[nonfree]                      allow nonfree and unredistributable libraries\n",
            "opencv3[openexr]                      OpenEXR support for opencv\n",
            "opencv3[opengl]                       opengl support for opencv\n",
            "opencv3[ovis]                         opencv_ovis module\n",
            "opencv3[png]                          PNG support for opencv\n",
            "opencv3[qt]                           Qt GUI support for opencv\n",
            "opencv3[quirc]                        Enable QR code module\n",
            "opencv3[sfm]                          opencv_sfm module\n",
            "opencv3[tbb]                          Enable Intel Threading Building Blocks\n",
            "opencv3[tiff]                         TIFF support for opencv\n",
            "opencv3[vtk]                          vtk support for opencv\n",
            "opencv3[webp]                         WebP support for opencv\n",
            "opencv3[world]                        Compile to a single package support for opencv\n",
            "opencv4              4.5.1#1          computer vision library\n",
            "opencv4[ade]                          graph api\n",
            "opencv4[contrib]                      opencv_contrib module\n",
            "opencv4[cuda]                         CUDA support for opencv\n",
            "opencv4[dnn]                          Enable dnn module\n",
            "opencv4[eigen]                        Eigen support for opencv\n",
            "opencv4[ffmpeg]                       ffmpeg support for opencv\n",
            "opencv4[gdcm]                         GDCM support for opencv\n",
            "opencv4[halide]                       Halide support for opencv\n",
            "opencv4[ipp]                          Enable Intel Integrated Performance Primitives\n",
            "opencv4[jasper]                       JPEG 2000 support for opencv\n",
            "opencv4[jpeg]                         JPEG support for opencv\n",
            "opencv4[lapack]                       LAPACK support for opencv\n",
            "opencv4[nonfree]                      allow nonfree and unredistributable libraries\n",
            "opencv4[openexr]                      OpenEXR support for opencv\n",
            "opencv4[opengl]                       opengl support for opencv\n",
            "opencv4[openmp]                       Enable openmp support for opencv\n",
            "opencv4[ovis]                         opencv_ovis module\n",
            "opencv4[png]                          PNG support for opencv\n",
            "opencv4[qt]                           Qt GUI support for opencv\n",
            "opencv4[quirc]                        Enable QR code module\n",
            "opencv4[sfm]                          opencv_sfm module\n",
            "opencv4[tbb]                          Enable Intel Threading Building Blocks\n",
            "opencv4[tiff]                         TIFF support for opencv\n",
            "opencv4[vtk]                          vtk support for opencv\n",
            "opencv4[webp]                         WebP support for opencv\n",
            "opencv4[world]                        Compile to a single package support for opencv\n",
            "openimageio[opencv]                   Enable opencv support for openimageio\n",
            "openmvg[opencv]                       opencv support for openmvg\n",
            "selene[opencv]                        Enable using OpenCV\n",
            "zxing-cpp[opencv]                     Build with opencv\n",
            "\n",
            "If your library is not listed, please open an issue at and/or consider making a pull request:\n",
            "    https://github.com/Microsoft/vcpkg/issues\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sm6J17TCEf2q",
        "outputId": "c5417201-50a4-4c99-9660-f61fc50fabb2"
      },
      "source": [
        "!./vcpkg/vcpkg install opencv4[jpeg]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>⌛ 30 min 51 s (2021-06-01T10:24:15)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Computing installation plan...\n",
            "The following packages will be built and installed:\n",
            "    opencv4[core,dnn,jpeg,png,quirc,tiff,webp]:x64-linux -> 4.5.1#1\n",
            "  * protobuf[core]:x64-linux -> 3.15.8#1\n",
            "  * quirc[core]:x64-linux -> 1.1#2\n",
            "  * tiff[core]:x64-linux -> 4.1.0#2\n",
            "Additional packages (*) will be modified to complete this operation.\n",
            "Detecting compiler hash for triplet x64-linux...\n",
            "Could not locate cached archive: /root/.cache/vcpkg/archives/2a/2a135def0cd99f0de8f098170888a2a3a96a46c6.zip\n",
            "Could not locate cached archive: /root/.cache/vcpkg/archives/f9/f92a1d82e97548fb0e6d6c3054597ba450a99ea2.zip\n",
            "Could not locate cached archive: /root/.cache/vcpkg/archives/34/3490656b361758c292079aa3378b573014f9edcd.zip\n",
            "Could not locate cached archive: /root/.cache/vcpkg/archives/dc/dcab80a00cc7e9838b2f92799f1b4d67d051267b.zip\n",
            "Starting package 1/4: protobuf:x64-linux\n",
            "Building package protobuf[core]:x64-linux...\n",
            "-- Using cached /content/vcpkg/downloads/protocolbuffers-protobuf-436bd7880e458532901c58f4d9d1ea23fa7edd52.tar.gz\n",
            "-- Cleaning sources at /content/vcpkg/buildtrees/protobuf/src/23fa7edd52-3ba2225d30.clean. Use --editable to skip cleaning for the packages you specify.\n",
            "-- Extracting source /content/vcpkg/downloads/protocolbuffers-protobuf-436bd7880e458532901c58f4d9d1ea23fa7edd52.tar.gz\n",
            "-- Applying patch fix-static-build.patch\n",
            "-- Applying patch fix-default-proto-file-path.patch\n",
            "-- Using source at /content/vcpkg/buildtrees/protobuf/src/23fa7edd52-3ba2225d30.clean\n",
            "-- Configuring x64-linux-dbg\n",
            "-- Configuring x64-linux-rel\n",
            "-- Building x64-linux-dbg\n",
            "-- Building x64-linux-rel\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/protobuf_x64-linux/lib/pkgconfig/protobuf-lite.pc\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/protobuf_x64-linux/lib/pkgconfig/protobuf.pc\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/protobuf_x64-linux/debug/lib/pkgconfig/protobuf-lite.pc\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/protobuf_x64-linux/debug/lib/pkgconfig/protobuf.pc\n",
            "-- Installing: /content/vcpkg/packages/protobuf_x64-linux/share/protobuf/copyright\n",
            "-- Performing post-build validation\n",
            "-- Performing post-build validation done\n",
            "Stored binary cache: /root/.cache/vcpkg/archives/2a/2a135def0cd99f0de8f098170888a2a3a96a46c6.zip\n",
            "Building package protobuf[core]:x64-linux... done\n",
            "Installing package protobuf[core]:x64-linux...\n",
            "Installing package protobuf[core]:x64-linux... done\n",
            "Elapsed time for package protobuf:x64-linux: 8.404 min\n",
            "Starting package 2/4: quirc:x64-linux\n",
            "Building package quirc[core]:x64-linux...\n",
            "-- Downloading https://github.com/dlbeer/quirc/archive/7e7ab596e4d0988faf1c12ae89c354b114181c40.tar.gz -> dlbeer-quirc-7e7ab596e4d0988faf1c12ae89c354b114181c40.tar.gz...\n",
            "-- Extracting source /content/vcpkg/downloads/dlbeer-quirc-7e7ab596e4d0988faf1c12ae89c354b114181c40.tar.gz\n",
            "-- Using source at /content/vcpkg/buildtrees/quirc/src/b114181c40-f1e71e0d5b.clean\n",
            "-- Configuring x64-linux-dbg\n",
            "-- Configuring x64-linux-rel\n",
            "-- Building x64-linux-dbg\n",
            "-- Building x64-linux-rel\n",
            "-- Installing: /content/vcpkg/packages/quirc_x64-linux/share/quirc/copyright/LICENSE\n",
            "-- Performing post-build validation\n",
            "-- Performing post-build validation done\n",
            "Stored binary cache: /root/.cache/vcpkg/archives/f9/f92a1d82e97548fb0e6d6c3054597ba450a99ea2.zip\n",
            "Building package quirc[core]:x64-linux... done\n",
            "Installing package quirc[core]:x64-linux...\n",
            "Installing package quirc[core]:x64-linux... done\n",
            "Elapsed time for package quirc:x64-linux: 3.378 s\n",
            "Starting package 3/4: tiff:x64-linux\n",
            "Building package tiff[core]:x64-linux...\n",
            "-- Downloading http://download.osgeo.org/libtiff/tiff-4.1.0.tar.gz -> tiff-4.1.0.tar.gz...\n",
            "-- Extracting source /content/vcpkg/downloads/tiff-4.1.0.tar.gz\n",
            "-- Applying patch fix-stddef.patch\n",
            "-- Applying patch cmakelists.patch\n",
            "-- Using source at /content/vcpkg/buildtrees/tiff/src/4.1.0-f65af59870.clean\n",
            "CMake Deprecation Warning at scripts/cmake/vcpkg_check_features.cmake:182 (message):\n",
            "  calling `vcpkg_check_features` without the `FEATURES` keyword has been\n",
            "  deprecated.\n",
            "\n",
            "      Please add the `FEATURES` keyword to the call.\n",
            "Call Stack (most recent call first):\n",
            "  ports/tiff/portfile.cmake:22 (vcpkg_check_features)\n",
            "  scripts/ports.cmake:139 (include)\n",
            "\n",
            "\n",
            "-- Configuring x64-linux-dbg\n",
            "-- Configuring x64-linux-rel\n",
            "-- Building x64-linux-dbg\n",
            "-- Building x64-linux-rel\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/tiff_x64-linux/lib/pkgconfig/libtiff-4.pc\n",
            "-- Fixing pkgconfig file: /content/vcpkg/packages/tiff_x64-linux/debug/lib/pkgconfig/libtiff-4.pc\n",
            "-- Installing: /content/vcpkg/packages/tiff_x64-linux/share/tiff/copyright\n",
            "-- Performing post-build validation\n",
            "-- Performing post-build validation done\n",
            "Stored binary cache: /root/.cache/vcpkg/archives/34/3490656b361758c292079aa3378b573014f9edcd.zip\n",
            "Building package tiff[core]:x64-linux... done\n",
            "Installing package tiff[core]:x64-linux...\n",
            "Installing package tiff[core]:x64-linux... done\n",
            "Elapsed time for package tiff:x64-linux: 22.67 s\n",
            "Starting package 4/4: opencv4:x64-linux\n",
            "Building package opencv4[core,dnn,jpeg,png,quirc,tiff,webp]:x64-linux...\n",
            "-- Downloading https://github.com/opencv/opencv/archive/4.5.1.tar.gz -> opencv-opencv-4.5.1.tar.gz...\n",
            "-- Extracting source /content/vcpkg/downloads/opencv-opencv-4.5.1.tar.gz\n",
            "-- Applying patch 0001-disable-downloading.patch\n",
            "-- Applying patch 0002-install-options.patch\n",
            "-- Applying patch 0003-force-package-requirements.patch\n",
            "-- Applying patch 0004-fix-policy-CMP0057.patch\n",
            "-- Applying patch 0005-fix-eigen.patch\n",
            "-- Applying patch 0006-fix-uwp.patch\n",
            "-- Applying patch 0008-devendor-quirc.patch\n",
            "-- Using source at /content/vcpkg/buildtrees/opencv4/src/4.5.1-e92f755db3.clean\n",
            "CMake Deprecation Warning at scripts/cmake/vcpkg_check_features.cmake:182 (message):\n",
            "  calling `vcpkg_check_features` without the `FEATURES` keyword has been\n",
            "  deprecated.\n",
            "\n",
            "      Please add the `FEATURES` keyword to the call.\n",
            "Call Stack (most recent call first):\n",
            "  ports/opencv4/portfile.cmake:43 (vcpkg_check_features)\n",
            "  scripts/ports.cmake:139 (include)\n",
            "\n",
            "\n",
            "-- Downloading https://github.com/tiny-dnn/tiny-dnn/archive/v1.0.0a3.tar.gz -> opencv-cache/tiny_dnn/adb1c512e09ca2c7a6faef36f9c53e59-v1.0.0a3.tar.gz...\n",
            "-- Configuring x64-linux-dbg\n",
            "-- Configuring x64-linux-rel\n",
            "-- Building x64-linux-dbg\n",
            "-- Building x64-linux-rel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "nj8k_ltOQWcv",
        "outputId": "1bebf267-36cc-4109-8099-07bbcade3fe7"
      },
      "source": [
        "# !/content/vcpkg/vcpkg export opencv4[jpeg] --zip"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 39 s (2021-06-01T11:08:21/2021-06-01T11:09:00)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The following packages are already built and will be exported:\n",
            "  * libjpeg-turbo:x64-linux\n",
            "  * liblzma:x64-linux\n",
            "  * libpng:x64-linux\n",
            "  * libwebp:x64-linux\n",
            "    opencv4:x64-linux\n",
            "  * protobuf:x64-linux\n",
            "  * quirc:x64-linux\n",
            "  * tiff:x64-linux\n",
            "  * zlib:x64-linux\n",
            "Additional packages (*) need to be exported to complete this operation.\n",
            "Exporting package libjpeg-turbo:x64-linux...\n",
            "Exporting package zlib:x64-linux...\n",
            "Exporting package libpng:x64-linux...\n",
            "Exporting package libwebp:x64-linux...\n",
            "Exporting package protobuf:x64-linux...\n",
            "Exporting package quirc:x64-linux...\n",
            "Exporting package liblzma:x64-linux...\n",
            "Exporting package tiff:x64-linux...\n",
            "Exporting package opencv4:x64-linux...\n",
            "Creating zip archive...\n",
            "Zip archive exported at: /content/vcpkg/vcpkg-export-20210601-110821.zip\n",
            "\n",
            "To use the exported libraries in CMake projects use:\n",
            "    -DCMAKE_TOOLCHAIN_FILE=[...]/scripts/buildsystems/vcpkg.cmake\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h4X5jHIrYxT"
      },
      "source": [
        "### Define ncnn Face detector in cpp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "x77j0eM-myKW",
        "outputId": "4812b05e-bf0d-48de-d084-5bb1301a767c"
      },
      "source": [
        "#@title FaceDetector.h\n",
        "\n",
        "%%writefile /content/FaceDetector.h\n",
        "\n",
        "#include \"net.h\"\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "#include <opencv2/core/core.hpp>\n",
        "#include <opencv2/highgui/highgui.hpp>\n",
        "#include <opencv2/imgproc/imgproc.hpp>\n",
        "#include <stdio.h>\n",
        "#include <vector>\n",
        "\n",
        "struct FaceObject\n",
        "{\n",
        "    cv::Rect_<float> rect;\n",
        "    cv::Point2f landmark[5];\n",
        "    float prob;\n",
        "};\n",
        "\n",
        "\n",
        "class NcnnFaceDetector {\n",
        "\n",
        "    protected:\n",
        "\n",
        "        inline float intersection_area(const FaceObject& a, const FaceObject& b);\n",
        "\n",
        "        void qsort_descent_inplace(std::vector<FaceObject>& faceobjects, int left, int right);\n",
        "\n",
        "        void qsort_descent_inplace(std::vector<FaceObject>& faceobjects);\n",
        "\n",
        "        void nms_sorted_bboxes(const std::vector<FaceObject>& faceobjects, std::vector<int>& picked, float nms_threshold);\n",
        "\n",
        "        ncnn::Mat generate_anchors(int base_size, const ncnn::Mat& ratios, const ncnn::Mat& scales);\n",
        "\n",
        "        void generate_proposals(const ncnn::Mat& anchors, int feat_stride, const ncnn::Mat& score_blob, const ncnn::Mat& bbox_blob, const ncnn::Mat& landmark_blob, float prob_threshold, std::vector<FaceObject>& faceobjects);\n",
        "\n",
        "    public:\n",
        "        NcnnFaceDetector();\n",
        "\n",
        "        ncnn::Net retinaface;\n",
        "\n",
        "        int detect_retinaface(const cv::Mat& bgr, std::vector<FaceObject>& faceobjects);\n",
        "\n",
        "};"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 6.78 ms (2021-06-01T11:37:04/2021-06-01T11:37:04)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/FaceDetector.h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "wLXr2qb3m_Zu",
        "outputId": "7e7a4aac-ae33-4bb8-b98c-762f71231d3e"
      },
      "source": [
        "#@title FaceDetector.cpp\n",
        "\n",
        "%%writefile /content/FaceDetector.cpp\n",
        "\n",
        "\n",
        "// TODO:  Debug Facedetector\n",
        "// Static method vs class methods getting diffrent cordinates in facebox\n",
        "\n",
        "\n",
        "#include \"FaceDetector.h\"\n",
        "\n",
        "\n",
        "NcnnFaceDetector::NcnnFaceDetector() {\n",
        "    \n",
        "    retinaface.opt.use_vulkan_compute = false;\n",
        "\n",
        "    // model is converted from\n",
        "    // https://github.com/deepinsight/insightface/tree/master/RetinaFace#retinaface-pretrained-models\n",
        "    // https://github.com/deepinsight/insightface/issues/669\n",
        "    // the ncnn model https://github.com/nihui/ncnn-assets/tree/master/models\n",
        "    //     retinaface.load_param(\"retinaface-R50.param\");\n",
        "    //     retinaface.load_model(\"retinaface-R50.bin\");\n",
        "\n",
        "    // Liveness modles are very sensitive to face cordinates\n",
        "    // Tested many lightweight models -- but only Resnet 50 found accurate and liveness models are working fine\n",
        "    // Getting same results on any device after using resnet 50\n",
        "\n",
        "    // // resnet 50 model converted from mxnet using ncnn utility and uploaded to drive\n",
        "    // retinaface.load_param(\"/usr/share/face_recognition/models/detection/retinaface-R50.param\");\n",
        "    // retinaface.load_model(\"/usr/share/face_recognition/models/detection/retinaface-R50.bin\");\n",
        "    // in colab\n",
        "    retinaface.load_param(\"/root/retinaface-R50.param\");\n",
        "    retinaface.load_model(\"/root/retinaface-R50.bin\");\n",
        "\n",
        "    //// mobilenet face detector  mostly gives diffrent faceboxes on diffrent os\n",
        "    // Also python and c++ version also gives diffrent results in many cases\n",
        "    // retinaface.load_param(\"/usr/share/face_recognition/models/detection/mnet.25-opt.param\");\n",
        "    // retinaface.load_model(\"/usr/share/face_recognition/models/detection/mnet.25-opt.bin\");\n",
        "\n",
        "    std::cout << \"Loaded ncnn face detector... \" << std::endl;\n",
        "}\n",
        "\n",
        "inline float NcnnFaceDetector::intersection_area(const FaceObject& a, const FaceObject& b) {\n",
        "    cv::Rect_<float> inter = a.rect & b.rect;\n",
        "    return inter.area();\n",
        "}\n",
        "\n",
        "void NcnnFaceDetector::qsort_descent_inplace(std::vector<FaceObject>& faceobjects, int left, int right)\n",
        "{\n",
        "    int i = left;\n",
        "    int j = right;\n",
        "    float p = faceobjects[(left + right) / 2].prob;\n",
        "\n",
        "    while (i <= j)\n",
        "    {\n",
        "        while (faceobjects[i].prob > p)\n",
        "            i++;\n",
        "\n",
        "        while (faceobjects[j].prob < p)\n",
        "            j--;\n",
        "\n",
        "        if (i <= j)\n",
        "        {\n",
        "            // swap\n",
        "            std::swap(faceobjects[i], faceobjects[j]);\n",
        "\n",
        "            i++;\n",
        "            j--;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    #pragma omp parallel sections\n",
        "    {\n",
        "        #pragma omp section\n",
        "        {\n",
        "            if (left < j) qsort_descent_inplace(faceobjects, left, j);\n",
        "        }\n",
        "        #pragma omp section\n",
        "        {\n",
        "            if (i < right) qsort_descent_inplace(faceobjects, i, right);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void NcnnFaceDetector::qsort_descent_inplace(std::vector<FaceObject>& faceobjects)\n",
        "{\n",
        "    if (faceobjects.empty())\n",
        "        return;\n",
        "\n",
        "    qsort_descent_inplace(faceobjects, 0, faceobjects.size() - 1);\n",
        "}\n",
        "\n",
        "void NcnnFaceDetector::nms_sorted_bboxes(const std::vector<FaceObject>& faceobjects, std::vector<int>& picked, float nms_threshold)\n",
        "{\n",
        "    picked.clear();\n",
        "\n",
        "    const int n = faceobjects.size();\n",
        "\n",
        "    std::vector<float> areas(n);\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        areas[i] = faceobjects[i].rect.area();\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        const FaceObject& a = faceobjects[i];\n",
        "\n",
        "        int keep = 1;\n",
        "        for (int j = 0; j < (int)picked.size(); j++)\n",
        "        {\n",
        "            const FaceObject& b = faceobjects[picked[j]];\n",
        "\n",
        "            // intersection over union\n",
        "            float inter_area = intersection_area(a, b);\n",
        "            float union_area = areas[i] + areas[picked[j]] - inter_area;\n",
        "            //             float IoU = inter_area / union_area\n",
        "            if (inter_area / union_area > nms_threshold)\n",
        "                keep = 0;\n",
        "        }\n",
        "\n",
        "        if (keep)\n",
        "            picked.push_back(i);\n",
        "    }\n",
        "}\n",
        "\n",
        "// copy from src/layer/proposal.cpp\n",
        "ncnn::Mat NcnnFaceDetector::generate_anchors(int base_size, const ncnn::Mat& ratios, const ncnn::Mat& scales)\n",
        "{\n",
        "    int num_ratio = ratios.w;\n",
        "    int num_scale = scales.w;\n",
        "\n",
        "    ncnn::Mat anchors;\n",
        "    anchors.create(4, num_ratio * num_scale);\n",
        "\n",
        "    const float cx = base_size * 0.5f;\n",
        "    const float cy = base_size * 0.5f;\n",
        "\n",
        "    for (int i = 0; i < num_ratio; i++)\n",
        "    {\n",
        "        float ar = ratios[i];\n",
        "\n",
        "        int r_w = round(base_size / sqrt(ar));\n",
        "        int r_h = round(r_w * ar); //round(base_size * sqrt(ar));\n",
        "\n",
        "        for (int j = 0; j < num_scale; j++)\n",
        "        {\n",
        "            float scale = scales[j];\n",
        "\n",
        "            float rs_w = r_w * scale;\n",
        "            float rs_h = r_h * scale;\n",
        "\n",
        "            float* anchor = anchors.row(i * num_scale + j);\n",
        "\n",
        "            anchor[0] = cx - rs_w * 0.5f;\n",
        "            anchor[1] = cy - rs_h * 0.5f;\n",
        "            anchor[2] = cx + rs_w * 0.5f;\n",
        "            anchor[3] = cy + rs_h * 0.5f;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return anchors;\n",
        "}\n",
        "\n",
        "void NcnnFaceDetector::generate_proposals(const ncnn::Mat& anchors, int feat_stride, const ncnn::Mat& score_blob, const ncnn::Mat& bbox_blob, const ncnn::Mat& landmark_blob, float prob_threshold, std::vector<FaceObject>& faceobjects)\n",
        "{\n",
        "    int w = score_blob.w;\n",
        "    int h = score_blob.h;\n",
        "\n",
        "    // generate face proposal from bbox deltas and shifted anchors\n",
        "    const int num_anchors = anchors.h;\n",
        "\n",
        "    for (int q = 0; q < num_anchors; q++)\n",
        "    {\n",
        "        const float* anchor = anchors.row(q);\n",
        "\n",
        "        const ncnn::Mat score = score_blob.channel(q + num_anchors);\n",
        "        const ncnn::Mat bbox = bbox_blob.channel_range(q * 4, 4);\n",
        "        const ncnn::Mat landmark = landmark_blob.channel_range(q * 10, 10);\n",
        "\n",
        "        // shifted anchor\n",
        "        float anchor_y = anchor[1];\n",
        "\n",
        "        float anchor_w = anchor[2] - anchor[0];\n",
        "        float anchor_h = anchor[3] - anchor[1];\n",
        "\n",
        "        for (int i = 0; i < h; i++)\n",
        "        {\n",
        "            float anchor_x = anchor[0];\n",
        "\n",
        "            for (int j = 0; j < w; j++)\n",
        "            {\n",
        "                int index = i * w + j;\n",
        "\n",
        "                float prob = score[index];\n",
        "\n",
        "                if (prob >= prob_threshold)\n",
        "                {\n",
        "                    // apply center size\n",
        "                    float dx = bbox.channel(0)[index];\n",
        "                    float dy = bbox.channel(1)[index];\n",
        "                    float dw = bbox.channel(2)[index];\n",
        "                    float dh = bbox.channel(3)[index];\n",
        "\n",
        "                    float cx = anchor_x + anchor_w * 0.5f;\n",
        "                    float cy = anchor_y + anchor_h * 0.5f;\n",
        "\n",
        "                    float pb_cx = cx + anchor_w * dx;\n",
        "                    float pb_cy = cy + anchor_h * dy;\n",
        "\n",
        "                    float pb_w = anchor_w * exp(dw);\n",
        "                    float pb_h = anchor_h * exp(dh);\n",
        "\n",
        "                    float x0 = pb_cx - pb_w * 0.5f;\n",
        "                    float y0 = pb_cy - pb_h * 0.5f;\n",
        "                    float x1 = pb_cx + pb_w * 0.5f;\n",
        "                    float y1 = pb_cy + pb_h * 0.5f;\n",
        "\n",
        "                    FaceObject obj;\n",
        "                    obj.rect.x = x0;\n",
        "                    obj.rect.y = y0;\n",
        "                    obj.rect.width = x1 - x0 + 1;\n",
        "                    obj.rect.height = y1 - y0 + 1;\n",
        "                    obj.landmark[0].x = cx + (anchor_w + 1) * landmark.channel(0)[index];\n",
        "                    obj.landmark[0].y = cy + (anchor_h + 1) * landmark.channel(1)[index];\n",
        "                    obj.landmark[1].x = cx + (anchor_w + 1) * landmark.channel(2)[index];\n",
        "                    obj.landmark[1].y = cy + (anchor_h + 1) * landmark.channel(3)[index];\n",
        "                    obj.landmark[2].x = cx + (anchor_w + 1) * landmark.channel(4)[index];\n",
        "                    obj.landmark[2].y = cy + (anchor_h + 1) * landmark.channel(5)[index];\n",
        "                    obj.landmark[3].x = cx + (anchor_w + 1) * landmark.channel(6)[index];\n",
        "                    obj.landmark[3].y = cy + (anchor_h + 1) * landmark.channel(7)[index];\n",
        "                    obj.landmark[4].x = cx + (anchor_w + 1) * landmark.channel(8)[index];\n",
        "                    obj.landmark[4].y = cy + (anchor_h + 1) * landmark.channel(9)[index];\n",
        "                    obj.prob = prob;\n",
        "\n",
        "                    faceobjects.push_back(obj);\n",
        "                }\n",
        "\n",
        "                anchor_x += feat_stride;\n",
        "            }\n",
        "\n",
        "            anchor_y += feat_stride;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int NcnnFaceDetector::detect_retinaface(const cv::Mat& bgr, std::vector<FaceObject>& faceobjects)\n",
        "{\n",
        "    // ncnn::Net retinaface;\n",
        "\n",
        "    // retinaface.opt.use_vulkan_compute = true;\n",
        "    // // resnet 50 model converted from mxnet using ncnn utility and uploaded to drive\n",
        "    // retinaface.load_param(\"/usr/share/face_recognition/models/detection/retinaface-R50.param\");\n",
        "    // retinaface.load_model(\"/usr/share/face_recognition/models/detection/retinaface-R50.bin\");\n",
        "\n",
        "    // // retinaface.load_param(\"/usr/share/face_recognition/models/detection/mnet.25-opt.param\");\n",
        "    // // retinaface.load_model(\"/usr/share/face_recognition/models/detection/mnet.25-opt.bin\");\n",
        "\n",
        "    const float prob_threshold = 0.8f;\n",
        "    const float nms_threshold = 0.4f;\n",
        "\n",
        "    int img_w = bgr.cols;\n",
        "    int img_h = bgr.rows;\n",
        "\n",
        "    ncnn::Mat in = ncnn::Mat::from_pixels(bgr.data, ncnn::Mat::PIXEL_BGR2RGB, img_w, img_h);\n",
        "\n",
        "    ncnn::Extractor ex = retinaface.create_extractor();\n",
        "\n",
        "    ex.input(\"data\", in);\n",
        "\n",
        "    std::vector<FaceObject> faceproposals;\n",
        "\n",
        "    // stride 32\n",
        "    {\n",
        "        ncnn::Mat score_blob, bbox_blob, landmark_blob;\n",
        "        ex.extract(\"face_rpn_cls_prob_reshape_stride32\", score_blob);\n",
        "        ex.extract(\"face_rpn_bbox_pred_stride32\", bbox_blob);\n",
        "        ex.extract(\"face_rpn_landmark_pred_stride32\", landmark_blob);\n",
        "\n",
        "        const int base_size = 16;\n",
        "        const int feat_stride = 32;\n",
        "        ncnn::Mat ratios(1);\n",
        "        ratios[0] = 1.f;\n",
        "        ncnn::Mat scales(2);\n",
        "        scales[0] = 32.f;\n",
        "        scales[1] = 16.f;\n",
        "        ncnn::Mat anchors = generate_anchors(base_size, ratios, scales);\n",
        "\n",
        "        std::vector<FaceObject> faceobjects32;\n",
        "        generate_proposals(anchors, feat_stride, score_blob, bbox_blob, landmark_blob, prob_threshold, faceobjects32);\n",
        "\n",
        "        faceproposals.insert(faceproposals.end(), faceobjects32.begin(), faceobjects32.end());\n",
        "    }\n",
        "\n",
        "    // stride 16\n",
        "    {\n",
        "        ncnn::Mat score_blob, bbox_blob, landmark_blob;\n",
        "        ex.extract(\"face_rpn_cls_prob_reshape_stride16\", score_blob);\n",
        "        ex.extract(\"face_rpn_bbox_pred_stride16\", bbox_blob);\n",
        "        ex.extract(\"face_rpn_landmark_pred_stride16\", landmark_blob);\n",
        "\n",
        "        const int base_size = 16;\n",
        "        const int feat_stride = 16;\n",
        "        ncnn::Mat ratios(1);\n",
        "        ratios[0] = 1.f;\n",
        "        ncnn::Mat scales(2);\n",
        "        scales[0] = 8.f;\n",
        "        scales[1] = 4.f;\n",
        "        ncnn::Mat anchors = generate_anchors(base_size, ratios, scales);\n",
        "\n",
        "        std::vector<FaceObject> faceobjects16;\n",
        "        generate_proposals(anchors, feat_stride, score_blob, bbox_blob, landmark_blob, prob_threshold, faceobjects16);\n",
        "\n",
        "        faceproposals.insert(faceproposals.end(), faceobjects16.begin(), faceobjects16.end());\n",
        "    }\n",
        "\n",
        "    // stride 8\n",
        "    {\n",
        "        ncnn::Mat score_blob, bbox_blob, landmark_blob;\n",
        "        ex.extract(\"face_rpn_cls_prob_reshape_stride8\", score_blob);\n",
        "        ex.extract(\"face_rpn_bbox_pred_stride8\", bbox_blob);\n",
        "        ex.extract(\"face_rpn_landmark_pred_stride8\", landmark_blob);\n",
        "\n",
        "        const int base_size = 16;\n",
        "        const int feat_stride = 8;\n",
        "        ncnn::Mat ratios(1);\n",
        "        ratios[0] = 1.f;\n",
        "        ncnn::Mat scales(2);\n",
        "        scales[0] = 2.f;\n",
        "        scales[1] = 1.f;\n",
        "        ncnn::Mat anchors = generate_anchors(base_size, ratios, scales);\n",
        "\n",
        "        std::vector<FaceObject> faceobjects8;\n",
        "        generate_proposals(anchors, feat_stride, score_blob, bbox_blob, landmark_blob, prob_threshold, faceobjects8);\n",
        "\n",
        "        faceproposals.insert(faceproposals.end(), faceobjects8.begin(), faceobjects8.end());\n",
        "    }\n",
        "\n",
        "    // sort all proposals by score from highest to lowest\n",
        "    qsort_descent_inplace(faceproposals);\n",
        "    \n",
        "    // apply nms with nms_threshold\n",
        "    std::vector<int> picked;\n",
        "    nms_sorted_bboxes(faceproposals, picked, nms_threshold);\n",
        "\n",
        "    int face_count = picked.size();\n",
        "\n",
        "    faceobjects.resize(face_count);\n",
        "    for (int i = 0; i < face_count; i++)\n",
        "    {\n",
        "        faceobjects[i] = faceproposals[picked[i]];\n",
        "\n",
        "        // clip to image size\n",
        "        float x0 = faceobjects[i].rect.x;\n",
        "        float y0 = faceobjects[i].rect.y;\n",
        "        float x1 = x0 + faceobjects[i].rect.width;\n",
        "        float y1 = y0 + faceobjects[i].rect.height;\n",
        "\n",
        "        x0 = std::max(std::min(x0, (float)img_w - 1), 0.f);\n",
        "        y0 = std::max(std::min(y0, (float)img_h - 1), 0.f);\n",
        "        x1 = std::max(std::min(x1, (float)img_w - 1), 0.f);\n",
        "        y1 = std::max(std::min(y1, (float)img_h - 1), 0.f);\n",
        "\n",
        "        faceobjects[i].rect.x = x0;\n",
        "        faceobjects[i].rect.y = y0;\n",
        "        faceobjects[i].rect.width = x1 - x0;\n",
        "        faceobjects[i].rect.height = y1 - y0;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// static void draw_faceobjects(const cv::Mat& bgr, const std::vector<FaceObject>& faceobjects)\n",
        "// {\n",
        "//     cv::Mat image = bgr.clone();\n",
        "\n",
        "//     for (size_t i = 0; i < faceobjects.size(); i++)\n",
        "//     {\n",
        "//         const FaceObject& obj = faceobjects[i];\n",
        "\n",
        "//         fprintf(stderr, \"%.5f at %.2f %.2f %.2f x %.2f\\n\", obj.prob,\n",
        "//                 obj.rect.x, obj.rect.y, obj.rect.width, obj.rect.height);\n",
        "\n",
        "//         cv::rectangle(image, obj.rect, cv::Scalar(0, 255, 0));\n",
        "\n",
        "//         cv::circle(image, obj.landmark[0], 2, cv::Scalar(0, 255, 255), -1);\n",
        "//         cv::circle(image, obj.landmark[1], 2, cv::Scalar(0, 255, 255), -1);\n",
        "//         cv::circle(image, obj.landmark[2], 2, cv::Scalar(0, 255, 255), -1);\n",
        "//         cv::circle(image, obj.landmark[3], 2, cv::Scalar(0, 255, 255), -1);\n",
        "//         cv::circle(image, obj.landmark[4], 2, cv::Scalar(0, 255, 255), -1);\n",
        "\n",
        "//         char text[256];\n",
        "//         sprintf(text, \"%.1f%%\", obj.prob * 100);\n",
        "\n",
        "//         int baseLine = 0;\n",
        "//         cv::Size label_size = cv::getTextSize(text, cv::FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseLine);\n",
        "\n",
        "//         int x = obj.rect.x;\n",
        "//         int y = obj.rect.y - label_size.height - baseLine;\n",
        "//         if (y < 0)\n",
        "//             y = 0;\n",
        "//         if (x + label_size.width > image.cols)\n",
        "//             x = image.cols - label_size.width;\n",
        "\n",
        "//         cv::rectangle(image, cv::Rect(cv::Point(x, y), cv::Size(label_size.width, label_size.height + baseLine)),\n",
        "//                       cv::Scalar(255, 255, 255), -1);\n",
        "\n",
        "//         cv::putText(image, text, cv::Point(x, y + label_size.height),\n",
        "//                     cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));\n",
        "//     }\n",
        "\n",
        "//     cv::imshow(\"image\", image);\n",
        "//     cv::waitKey(0);\n",
        "// }"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 21.9 ms (2021-06-01T11:53:28/2021-06-01T11:53:28)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/FaceDetector.cpp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "I2VjGxL_oVVg",
        "outputId": "5a3b0c18-6af8-44c8-b659-3ee968b4d246"
      },
      "source": [
        "#@title main_executable.cpp\n",
        "\n",
        "%%writefile /content/main_executable.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <cstdio>\n",
        "#include <string>\n",
        "#include <stdio.h>\n",
        "#include <algorithm>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <chrono> \n",
        "\n",
        "#include <opencv2/opencv.hpp>\n",
        "#include <opencv2/dnn.hpp>\n",
        "#include <opencv2/imgproc.hpp>\n",
        "#include \"FaceDetector.h\"\n",
        "\n",
        "using namespace cv;\n",
        "using namespace dnn;\n",
        "using namespace std;\n",
        "using namespace std::chrono; \n",
        "\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    std::cout << \"Hello from main..\" << std::endl;\n",
        "\n",
        "    string image_file;\n",
        "    if  (argc == 1)\n",
        "    {\n",
        "        image_file = \"/content/pan-card-500x500.jpg\";\n",
        "    }\n",
        "    else if (argc == 2)\n",
        "    {\n",
        "        image_file = argv[1];\n",
        "    }\n",
        "    std::cout << \"Processing \" << image_file << std::endl;\n",
        "\n",
        "    //// 2\n",
        "    /// flag value 1 to imread means -- cv2.IMREAD_COLOR:\n",
        "    /// It specifies to load a color image. \n",
        "    /// Any transparency of image will be neglected. It is the default flag. Alternatively, we can pass integer value 1 for this flag.\n",
        "    cv::Mat frame = cv::imread(image_file.c_str(), 1);\n",
        "\n",
        "    if (frame.empty())\n",
        "    {\n",
        "        fprintf(stderr, \"cv::imread %s failed\\n\", image_file.c_str());\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // //// 3\n",
        "    std::vector<FaceObject> faceobjects;\n",
        "    NcnnFaceDetector face_detector;\n",
        "    face_detector.detect_retinaface(frame, faceobjects);\n",
        "\n",
        "    std::cout << \"faceobjects[0].rect.x: \" << faceobjects[0].rect.x << std::endl;\n",
        "    std::cout << \"faceobjects[0].rect.y: \" << faceobjects[0].rect.y << std::endl;\n",
        "    std::cout << \"faceobjects[0].rect.width: \" << faceobjects[0].rect.width << std::endl;\n",
        "    std::cout << \"faceobjects[0].rect.height: \" << faceobjects[0].rect.height << std::endl;\n",
        "\n",
        "}"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 6.02 ms (2021-06-01T11:37:42/2021-06-01T11:37:42)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/main_executable.cpp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "MKOhjavnnYQT",
        "outputId": "fa99df63-33d1-4cfe-dd4c-3a131acfe052"
      },
      "source": [
        "#@title CMakeLists.txt\n",
        "\n",
        "%%writefile /content/CMakeLists.txt\n",
        "\n",
        "cmake_minimum_required(VERSION 3.9)\n",
        "set( CMAKE_TOOLCHAIN_FILE \"/content/vcpkg/scripts/buildsystems/vcpkg.cmake\" )\n",
        "\n",
        "project (liveness)\n",
        "\n",
        "add_definitions(-std=c++11)\n",
        "add_definitions(\"-Wall\")\n",
        "\n",
        "\n",
        "## Statically link-- os specific ncnn\n",
        "## more info: https://github.com/Tencent/ncnn/releases\n",
        "## cmake link -- https://github.com/Tencent/ncnn/wiki/use-ncnn-with-own-project\n",
        "\n",
        "# set install path of ncnn on your system\n",
        "set(NCNN_INSTALL_DIR \"/usr/local/c++/ncnn/build/install\")\n",
        "\n",
        "## install dir will be created after running 'make install' command in ncnn build dir\n",
        "set(ncnn_DIR \"${NCNN_INSTALL_DIR}/lib/cmake/ncnn\" CACHE PATH \"Directory that contains ncnnConfig.cmake\")\n",
        "find_package(ncnn REQUIRED)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# make executable for testing purpose\n",
        "# -----------------------------------------------------------------------------\n",
        "add_executable(retinaface\n",
        "\tFaceDetector.cpp \n",
        "\tFaceDetector.h \n",
        "\tmain_executable.cpp\n",
        ")\n",
        "\n",
        "# link ncnn // ncnn already defined above -- just use it\n",
        "target_link_libraries( retinaface  ncnn )\n",
        "\n",
        "# Find Package\n",
        "find_package( OpenCV REQUIRED )\n",
        "\n",
        "if( OpenCV_FOUND )\n",
        "  # Additional Include Directories\n",
        "  include_directories( ${OpenCV_INCLUDE_DIRS} )\n",
        "\n",
        "  # Additional Library Directories\n",
        "  link_directories( ${OpenCV_LIB_DIR} )\n",
        "\n",
        "  # Additional Dependencies\n",
        "  target_link_libraries( retinaface ${OpenCV_LIBS} )\n",
        "endif()\n",
        "\n",
        "# link opencv\n",
        "# target_link_libraries( retinaface ${OpenCV_LIBS} )"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 20.8 ms (2021-06-01T11:29:37/2021-06-01T11:29:37)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/CMakeLists.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "_2EVaGs8pSCj",
        "outputId": "954fff05-c6e9-404c-c2a6-77bcf6217424"
      },
      "source": [
        "!mkdir -p \"build\" \n",
        "%cd \"/content/build\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 125 ms (2021-06-01T11:05:50/2021-06-01T11:05:50)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "4JxCfXfkpVDH",
        "outputId": "36295fe1-45ac-4867-8137-c5cf8a2fc82d"
      },
      "source": [
        "!cmake ..\n",
        "!make -j$(nproc)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 5.35 s (2021-06-01T11:53:33/2021-06-01T11:53:38)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target retinaface\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/retinaface.dir/main_executable.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/retinaface.dir/FaceDetector.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable retinaface\u001b[0m\n",
            "[100%] Built target retinaface\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "mx0DOgNIqFF0",
        "outputId": "6d066592-37e0-4640-cfd4-ce1b1329a094"
      },
      "source": [
        "!./retinaface # \"/content/Woman Wearing White Shirt Waving Goodbye.jpg\""
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 2.02 s (2021-06-01T11:56:41/2021-06-01T11:56:43)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Hello from main..\n",
            "Processing /content/pan-card-500x500.jpg\n",
            "Loaded ncnn face detector... \n",
            "faceobjects[0].rect.x: 381.596\n",
            "faceobjects[0].rect.y: 208.707\n",
            "faceobjects[0].rect.width: 56.569\n",
            "faceobjects[0].rect.height: 71.1753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8HXbFSMblzZ"
      },
      "source": [
        "obj.rect.x: 802.1411844140878\n",
        "obj.rect.y: 149.21483296874882\n",
        "obj.rect.w: 342.480463813426\n",
        "obj.rect.h: 482.2495380496239"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVrzPmvZDpC"
      },
      "source": [
        "##############################################\n",
        "## 1\n",
        "### Python result\n",
        "# obj.rect.x: 381.5889571369823\n",
        "# obj.rect.y: 208.69838688128922\n",
        "# obj.rect.w: 56.583804476035425\n",
        "# obj.rect.h: 71.11885123742152\n",
        "\n",
        "# ## cpp retinaface result\n",
        "# faceobjects[0].rect.x 381.7\n",
        "# faceobjects[0].rect.y 208.248\n",
        "# faceobjects[0].rect.width 56.3604\n",
        "# faceobjects[0].rect.height 71.316\n",
        "\n",
        "##############################################\n",
        "## 2\n",
        "### Python result\n",
        "obj.rect.x: 808.7731370958414\n",
        "obj.rect.y: 151.8726988363982\n",
        "obj.rect.w: 339.32872580831724\n",
        "obj.rect.h: 487.12960232720366\n",
        "\n",
        "\n",
        "faceobjects[0].rect.x 817.64\n",
        "faceobjects[0].rect.y 145.44\n",
        "faceobjects[0].rect.width 337.845\n",
        "faceobjects[0].rect.height 488.139"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvcusLJFXxA6"
      },
      "source": [
        "[[382, 209, 57, 71, 0.9970703125]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "9c2P8g2oX1PV",
        "outputId": "33526054-97a1-4cf4-bb0d-8ace88c54013"
      },
      "source": [
        "import math\n",
        "math.ceil(56.3604)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre>✔️ 4.01 ms (2021-06-01T11:40:29/2021-06-01T11:40:29)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}
